# B端和服务端性能测试

## 一.软件性能测试基本概念

### 1.1.什么是软件性能

#### 1.1.1定义

**用户角度**：从客观的角度来说，事务的结束应该是系统返回所有的数据，相应时间应该是从用户操作开始到左右数据返回完成的整个耗时；

**优化策略1**:当少部分数据返回之后就立刻将数据呈现在用户面前，则用户感受到的响应时间就会远远小于实际的事务响应时间（这是在C/S结构的管理系统里面常用的一种技巧）

**管理员角度**：

![image-20190806104505191](/Users/apple/Library/Application Support/typora-user-images/image-20190806104505191.png)

**开发者角度**

![image-20190806111550286](/Users/apple/Library/Application Support/typora-user-images/image-20190806111550286.png)

#### 1.1.2 Web前端性能

**延伸**：web前端的响应时间主要是浏览器的展现和浏览器端脚本（如JS脚本）执行所消耗的时间，严格上来说，这个时间并非与服务端性能毫无关系。例如，大多数Ajax应用都会使用JS从服务器获取数据，获取数据所需要消耗的时间明显依赖于服务端性能的。然而，大多数情况下，由于Ajax本身的异步机制，这些时间消耗并不构成前端响应时间的主要部分，因此在讨论web前端性能时，并不特别关注这部分时间。

注意⚠️：

Web应用的前端响应时间指浏览器的页面加载时间。

与服务性能不同，前端性能与兵法用户量的大小并无非常直接的关系

### 1.2.软件性能的几个专业术语

#### 1.2.1响应时间

包含：前端响应时间，服务端响应时间，用户响应时间

服务端响应时间：应用系统从请求发出开始到客户端接收到最后一个字节所消耗的时间

![image-20190806142427839](/Users/apple/Library/Application Support/typora-user-images/image-20190806142427839.png)

**页面响应时间包括**：

网络传输时间：（N1+N2+N3+N4）

应用延迟时间：（A1+A2+A3）

其中，应用延迟时间包括：数据库延迟时间（A2）和应用服务延迟时间（A1+A2）

注意⚠️：在进行性能测试时，合理的响应时间取决于实际的用户需求，而不能依据测试人员的设想来决定。

#### 1.2.2用户并发数

**业务并发用户数**：在一个相当长的时间里，如果所有用户操作没有遇到性能阻碍，则可以说，该系统能够承受该数量的用户并发数；

**服务并发数**：在整个系统运行中，把系统运行划分成多个离散点，在每个离散点上，都有一个同时向服务端发送请求的客户数，如果能够找到运行过程中可能出现的服务最大可承受的并发访问数，则在该用户数下，服务器承受的压力最大，资源承受的压力最大，这种情况下可以通过并发测试发现系统中存在的并发引起的资源争用等问题。

估算并发用户数的公式：

​					C = nL / T											(1-1)

​					^C ≈ C + 3√C									（1-2）

在式（1-1）中，C是平均并发用户数，n是（用户从登陆进入系统到推出系统之间的时间段）的数量；L是（用户从登陆进入系统到推出系统之间的时间段）的平均长度：T指考察的时间段长度。例如，对一个典型的OA应用，考察的时间段长度应该为8个小时。

在式（1-2）则给出了并发用户数峰值的计算方式，其中，^C指并发用户数的峰值；C是式（1-1）中得到平均并发用户数。该公式是假设用户的（用户从登陆进入系统到推出系统之间的时间段）产生符合泊松分布而得到的。

**泊松分布就是描述某段时间内，事件具体的发生概率。**

实例：假设有一个OA系统，该系统有3000个用户，平均每天大约有400个用户要访问该系统，对一个典型用户来说，一天只在8小时内使用该系统，且从登陆到退出该系统的平均时间为4小时。

​			则根据（1-1）和（1-2），可以得到：

​							C = 400 x  4/8 = 200

​							^C ≈ 200+ 3√200 = 242

例如，如果能够知道平均每个用户发出的请求数（假设u），则系统的总吞吐量可估算为u*C

**精准的计算得到并发用户数的方法**

1.以更细的时间粒度，进行考察

2.考虑典型的业务场景

考虑安装AWStats（日志观察工具）

#### 1.2.3吞吐量

**吞吐量**：直接体现软件系统的承载能力，是指单位时间内系统处理的客户请求数量。

**吞吐量的重要性**:

对于交互式应用，用户直接的体验是‘响应时间’，通过‘并发用户数’和‘响应时间’可以确定系统的性能测试规划；但是对于非交互式应用，用'吞吐量'来描述用户对于系统的期望更加合理。

对于交互式应用来说，吞吐量指标反映的是服务承受的压力。在容量规划的测试中，吞吐量是一个重点关注的指标，因为他能够说明系统级别负载的能力。

针对性地对吞吐量设计测试，有助于尽快定位到性能测试瓶颈所在的位置。

**延伸**：在大部分性能测试工具的统计中，单击数（Hits）是指客户端发出的http请求的数量

作为性能测试时的主要关注指标，吞吐量和并发数之间存在一定的联系，在没有遇到性能瓶颈时，吞吐量可以采用如下公式计算：

​							F = N(VU)*R / T

其中，F表示吞吐量；N(VU)表示VU（虚拟用户）的个数；R表示每个VU发出的请求（单击）数量；T表示性能测试所需要的时间。但如果遇到了性能测试瓶颈，吞吐量和VU就不再符合公式给出的关系。

注意⚠️：吞吐量的瓶颈必须依据实际业务情况，其中：

并发用户数需要真实的用户个数

并发持续时间需要实际活动时长

这些都会影响到最终的性能测试瓶颈定位

例如：

对同一个应用进行2次不同的性能测试，测试A采用100个并发，每个VU间隔1秒发出一个请求；测试B采用1000个并发，每个VU间隔10秒发出一个请求。对于测试A的吞吐量（pages/sec）为100*1/1 = 100；对于测试B，吞吐量（pages/sec）为1000*1/10 = 100，二者相同。但是从测试结果上来看，执行测试A时，应用在50pages/sec出现性能瓶颈，而测试B则在25pages/sec出现瓶颈。

问题：

1.为什么同一个应用，吞吐量相同的情况下，测试出来两种性能瓶颈？

2.为什么输出的2种性能瓶颈，关系是测试A = 2*测试B

3.那个性能瓶颈是真实的性能瓶颈？

举例说明：用户数是一堵墙上的砖头，时间是我们从开始抽砖头到最终抽完的耗时。我们是从下面开始抽出来砖头，用户数越大，我们越是难以抽出砖头，约定的时间很难完成。这种难易程度就可以抽象成性能的瓶颈

#### 1.2.4性能计数器（资源利用率）

**性能计数器**：是描述服务器或操作系统性能的一些数据指标。

**性能计数器的作用**：

计数器在性能测试中发挥着监控和分析的的关键作用，尤其是在分析系统的可拓展性，进行性能瓶颈定位时，对计数器去值得分析非常关键。

注意⚠️：单一计数器只能体现系统的某一个方面，对性能测试结果的分析必须是基于多个不同的计数器。

在性能测试中常用资源利用率进行横向的对比，例如，在进行测试时发现，资源A的使用率接近100%，而其他资源的使用率都处于比较低的水平，则可以很清楚的知道，资源A很可能是系统的一个性能瓶颈。当然，资源利用率在更通常的情况下需要结合响应时间变化曲线，系统负载曲线等各种指标进行分析。

#### 1.2.5思考时间（休眠时间）

**思考时间**：从业务的角度来说，该时间指的是用户在进行操作时，每个请求之间的间隔时间。从测试的角度，在测试脚本中，思考时间体现为脚本中两个请求语句之间的间隔时间

其实，思考时间与迭代次数，并发用户数和吞吐量之间存在一定的关系。吞吐量是VU数量N（VU），每个用户发出请求数R和时间T的函数，其中的R又可以用时间T和用户的思考时间T(s):

​							R = T / T(s)

吞吐量与N（VU）成正比，与T(s)成反比。

注意⚠️：计算思考时间的一般方法：

1.首先计算出系统的并发用户数

2.统计数系统平均的吞吐量

3.统计出平均每用户发出的请求数量

4.依据以上的公式计算思考时间

**‘0思考时间’**：从业务的角度上考虑，思考时间用于更加真实的模拟用户操作，设置思考时间为0，基本上不具有实际的业务含义，这时是模拟一种尽可能大的压力，一研究系统在巨大的压力下的表现

如果了解系统在压力下的性能水平或系统承受压力的能力。

### 1.3.软件性能测试方法论

#### 1.3.1 SEI负载测试计划过程

SEI负载测试计划过程是一个关注于负载测试计划的方法，其目标是产生清晰、易理解、可验证的负载测试计划。SEI负载测试计划过程中包括6个关注的区域：目标、用户、用例、生产环境、测试环境和测试场景。

SEI负载测试计划过程将上述6个区域作为负载测试计划需要重点关注和考虑的内容，其重点关注以下几个方面的内容：

1.生产环境和测试环境的不同

由于负载测试环境和实际的生产环境存在一定的差异，因此，在测试环境上对应用系统进行的负载测试结果很可能不能准确反映该应用系统在生产环境上世纪性能表现，为了规避这个风险，必须仔细设计测试环境。

2.用户分析

用户是对被测应用系统性能表现最关注和受影响最大的对象，因此，必须通过对用户行为的分析，依据用户行为模型建立用例和场景。

3.用例

用例是用户使用某种顺序和操作方式对业务过程进行实现的过程，对负载测试来说，用例的作用主要在于分析和分解出关键的业务，判断每个业务发生的频度、业务出现性能问题的风险等。

#### 1.3.2 RBI方法

RBI方法是Empirix公司提出的一种用于快速识别系统性能瓶颈的方法。该方法基于以下一些事实：

（1）发现的80%系统的性能瓶颈都是由吞吐量制约。

（2）并发用户数和吞吐量瓶颈之间存在一定的关联。

（3）采用吞吐量测试可以更快速地定位问题。

RBI方法首先访问服务器上的‘小页面’和‘简单应用’，从应用服务器、网络等基础的层次上去了解系统吞吐量表现；其次选择不同的场景，设定不同的用户并发数，使其吞吐量保持基本一致的增长趋势，通过不断增加并发用户数和吞吐量，观察系统的性能表现。

在确定具体的性能瓶颈时，RBI将性能瓶颈的定位按照一种'自上而下‘的分析方式进行分析，首先确定是由吞吐量引发的性能表现限制，然后从网络、数据库、应用服务器和代码本身4个环节确定系统性能具体的瓶颈.

#### 1.3.3.性能下降曲线分析法

性能下降曲线世纪上是描述性能随着用户数的增加出现下降趋势的曲线。

![image-20190813165006619](/Users/apple/Library/Application Support/typora-user-images/image-20190813165006619.png)

因此，对性能下降曲线分析法来说，主要关注的是性能下降曲线上的各个区间和相应的拐点，通过识别不同的区间和拐点，为性能瓶颈识别和性能调优提供依据。

#### 1.3.4LoadRunner的性能测试过程

LoadRunner性能测试过程分为测试计划、测试设计、创建VU脚本、运行测试场景和分析结果6个步骤。

![image-20190813170818933](/Users/apple/Library/Application Support/typora-user-images/image-20190813170818933.png)

**计划测试阶段**：进行测试需求收集、典型场景的确定；

**测试设计阶段**：主要进行测试用例设计；

**创建VU脚本阶段**：主要根据设计的用例创建脚本；

**创建测试场景阶段**：主要进行测试场景的设计和设置；包括监控指标的设定；

**运行测试场景阶段**：主要对一创建的测试场景进行执行，收集响应数据；

**分析结果阶段**：主要进行结果的分析和报告工作。

#### 1.3.5 Segue的性能测试

Segue的性能测试过程是一个不断try-check的过程。

![image-20190813174320273](/Users/apple/Library/Application Support/typora-user-images/image-20190813174320273.png)

#### 1.3.6 敏捷性能测试

敏捷性能测试包含以下特点：

##### **1.每个迭代目标中包含明确的性能目标**

敏捷开发中性能测试和其他类型测试一样，需要以迭代为单位组织和管理性能测试，因此需要再每个迭代目标中明确定义迭代结束时可被验证的性能目标。由于一个迭代交付的产品并不一定具有完备的功能，因此在迭代目标中包含的性能目标并非完全建立在端到端响应时间上。

迭代目标中的性能目标可能是基于端到端的，也可能是基于接口的，甚至可能是面向具体的函数的。以下都是在迭代周期中可接受的性能描述：

=>在吞吐量为40QPS的情况下，X页面的服务响应时间小于5秒。

=>模块B能够每秒处理来自模块A的1000个请求

=>Employee从服务端获取给定employee信息的方法耗时不超过100毫秒

只有确定了每个迭代的性能目标，才有可能在每个迭代中安排合理的性能测试。需要采用相同的方式对迭代中的性能目标进行管理。

##### **2.建立不同层次的性能测试**

迭代目标中性能测试具有不同层次。这些性能目标可能是端到端，也可能是基于接口的，还可能是面向具体函数的。敏捷测试中可以使用不同的方法进行验证。

与单元测试一样，**函数级别的性能测试**对环境依赖性较小，对其他模块函数也不存在较强的依赖性，因此可以很容易地放置在持续集成中与其他单元测试一起运行。

**接口级别的性能测试**则需要较多环境的支持，一般来说，接口级别的性能测试至少要求将模块或子系统运行起来，并设置好测试的支持环境。

**端到端性能测试**需要更复杂的环境支持。考虑到端到端的性能测试结果与所在的环境存在极大的依赖性，这个层次的性能测试需要在严格定义的测试环境上运行。因此，通常需要为被测应用准备好‘一键部署’的脚本，只要通过一个命令行就能够将被测应用部署到制定环境上，然后使用合适的工具和脚本对其进行性能测试。

##### 3.完全活接近完全自动化的性能测试

敏捷测试极大的依赖于自动化测试，每个迭代中组织的性能测试，同样需要依赖自动化测试来达成。

性能测试中的自动化包括两个部分：**性能测试工具与脚本**，**以及用于设置环境的脚本**。市面上有很多商业和开源的性能测试工具，例如：LoadeRunner工具，JMeter工具，JUnit工具等。但是这些工具往往都不能直接帮助设置性能测试需要的环境，不能基于某个基线进行结果的比较。如果要在敏捷的性能测试中实现高度自动化，还需要其他自动化工具（如部署工具等）的支持。

##### 4.使用测试驱动方法保证性能与优化性能

测试驱动开发（TDD）促使开发工程师在实现代码之前准确定义代码功能，并通过这个准则避免开发工程师增加不必要的功能。

实际上，TDD方法同样适用于敏捷中的性能测试。如果有明确的针对函数的性能标准，该标准，同样可以背包含在测试中，并作为函数实现与否的一个判定辨准。

除了可以在函数级的性能测试中建立标准外，在更高层面简历持续的性能测试标准也是一个可用的实践。由于敏捷方法中需求变动比较频繁，难易建立一个确定的，持久的性能接受性标准。

对于没有明确定义性能标准的关键性能点，‘不低于上一个版本的性能表现’可以作为默认的性能约束，从而包含在每个迭代的验收标准中，甚至可以被放在持续集成或代码提交的标准中，以决定某个CL（Change List）是否可以被提交。

#### 1.3.7.本书提供的性能测试模型

非敏捷测试模型

![image-20190814164640580](/Users/apple/Library/Application Support/typora-user-images/image-20190814164640580.png)

## 二.性能测试的应用领域

### 2.1性能测试的方法

性能测试（Performance Testing）包括如下方法：

验收性能测试（Acceptance Performance Testing）

负载测试（ Load Testing）

压力测试（Stress Testing）

配置测试（Configuration Testing）

并发测试（Concurrency Testing）

可靠性测试（Reliability Testing）

失败恢复测试（Failover Testing）

#### 2.1.1.验收性能测试

验收性能测试（Acceptance Performance Testing）方法通过模拟生产运行的业务压力量和使用场景组合，测试系统的性能是否满足生产性能要求。这是一种最常见的测试方法，通俗地说，这种测试方法就要在特定的运行条件下验证系统的能力状况。

验收性能测试方法具有以下特点：

（1）这种方法的主要目的是验证系统是否具有系统宣称具有的能力

（2）这种方法需要事先了解被测试系统的典型场景，并且具有确定的性能目标

验收性能测试方法需要首先了解被测系统的典型场景，所谓的典型场景，是指具有代表性的用户业务操作，一个典型场景包括操作序列和并发用户数量条件。其次，这种方法需要有确定的性能目标，性能目标描述方式一般为：“要求系统在100个并发用户的条件下进行A业务操作，响应时间不超过5秒”

（3）这种方法要求在已确定的环境下进行

#### 2.1.2.负载测试

负载测试（Load Testing）方法在被测系统上不断增加压力，直到性能指标（如：响应时间）超过预定指标或者某种资源使用已经达到饱和状态。

负载测试方法可以找到系统的处理极限，为系统调优提供数据，有时也被称为可置性测试（Scalability Testing），该方法有如下特点：

（1）这种性能测试方法的主要目的是找到系统处理能力的极限。

负载测试检测方法通过“检测-加压-性能指标超过预期”的手段，找到系统处理能力的极限。一般性能要求会有业务描述例如：‘在给定条件下最多允许120个并发用户访问’或者是‘在给定的条件下最多能够在1小时以内处理2100笔业务’，一般要求‘响应时间不超过10秒’，‘服务器平均CPU65%’等等

（2）这种性能测试方法需要在给定的测试环境进行，通常也需要考虑被测系统的业务压力量和典型场景，使得测试结果具有业务上的意义

（3）这种性能测试方法一般用来了解系统的性能容量，或事配合性能调优来使用。

#### 2.1.3.压力测试

压力测试方法测试系统在一定饱和状态下，例如CPU、内存等在饱和使用情况下，系统能够处理会话能力，以及系统是否会出现错误。

压力测试方法具有一下特点：

（1）这种性能测试方法的主要目的是检查系统处于压力状况下时的性能表现。

（2）这种性能测试一般通过模拟负载等方法，使得系统的资源使用达到较高水平。

注意⚠️：压力测试内容（在CPU使用率达到75%以上，内存使用率达到70%以上）：JVM的可用内存、数据库连接数、数据库服务器CPU利用率等都可以作为压力的依据。

（3）这种性能测试一般用于测试系统的稳定性

#### 2.1.4.配置测试

配置测试方法通过对北侧系统软硬件环境的调整，了解各种不同环境对系统性能影响的程度，从而找到系统各项资源的最优分配原则。

（1）配置测试性能测试方法主要目的是了解各种不同因素对系统性能影响的程度，从而判断最值得进行的调优操作。

（2）这种性能测试方法一般在对系统性能这状况有初步了解后进行。

（3）这种性能测试方法一般用于性能调优和规划能力

#### 2.1.5.并发测试

并发测试方法通过模拟用户的并发访问，测试多用户并发访问同一个应用，同一个模块或者数据记录时是否存在思索或者其他性能问题。

并发测试具有以下特点：

（1）这种性能测试方法主要目的是发现系统中可能隐藏的并发访问时的问题。

（2）这种性能测试方法主要关注系统可能存在的并发问题，例如系统中的内存泄漏、线程锁和资源争用方面的问题。

![image-20190816200631245](/Users/apple/Library/Application Support/typora-user-images/image-20190816200631245.png)

（3）这种性能测试方法可以在开发的各个阶段使用，需要相关的测试工具的配合和支持。

#### 2.1.6可靠性测试

可靠性测试方法通过给系统加载一定的业务压力(例如资源在70%～90%的使用率)，让应用持续运行一段时间，测试系统在这种条件下能否稳定运行。

可靠性测试方法具有以下特点：

（1）这种性能测试方法的主要目的是验证系用是否长期稳定的运行。

（2）这种性能测试方法需要在压力下持续一段时间的运行。（一般大型项目需要在峰值压力下，进行2-3天的稳定性测试即可）

（3）测试过程中需要关注系统的运行情况。

#### 2.1.7失效恢复测试

失效恢复测试方法针对有冗余备份和负载均衡的系统设定的。这种测试方法可以检验如果系统局部发生故障，用户是否能够继续使用系统，以及如果情况发生，用户受到多大程度的影响。

失效恢复方法具有以下特点：

（1）这种性能测试方法主要目的是验证在局部故障情况下，系统能否继续使用。

（2）这种性能测试方法还需要指出，当问题发生时‘能支持多少用户访问’的结论和‘采用何种应急措施’的方案

（3）一般来说，只有对系统持续运行有明确要求的系统才需要进行这种类型的测试。

### 2.2性能测试应用领域分析

性能测试的应用领域划分为5个不同领域：

**能力验证**

**规划能力**

**性能调优**

**缺陷发现**

**性能基准比较**

#### 2.2.1能力验证

能力验证领域的特点与性能测试的特点非常接近：

（1）要求在已确定的环境下运行。

只有在一个确定的运行环境下，软件性能的承诺和规划才是有意义的。

（2）需要根据典型场景设计测试方案和用例。

能力验证需要了解被测系统的典型场景，并根据典型场景设计测试方案和用例。一个典型场景包括操作序号和并发用户数量条件。在设计用例时，需要确定相应的性能目标。

能力验证一般采用性能测试方法，一般包括性能测试、可靠性测试、压力测试和失效恢复测试方法。

#### 2.2.2规划能力

规划能力应用领域与能力验证应用领域有些不同，能力验证应用领域关心的是“在给定条件下，系统能否具有预期的能力表现”，而规划能力应用领域关心的是“应该如何使系统具有我们要求的性能能力”或是“在某种可能发生的条件下，系统具有如何的性能能力”。规划性能应用领域内的问题常常会被描述为：“某系统能否支持未来一段时间的用户增长”或是“应该如何调整系统配置，使系统能够满足增长的用户数的需要”

规划能力的特点：

（1）它是一种探索性的测试

（2）它可用于了解系统的性能以及获得拓展性能的方法。

用于规划能力领域的问题，常用的测试方法包括负载测试、配置测试和压力测试方法。

#### 2.2.3性能调优

性能调优的标准过程示意图：

![image-20190823111922461](/Users/apple/Library/Application Support/typora-user-images/image-20190823111922461.png)

一个标准的性能调优过程的描述如下：

 1）确定基准环境，基准负载和基准性能指标。

注意⚠️：实际的性能调优过程中常见的错误包括以下几种：

（1）没有保证每次执行时的数据库具有相同的数据环境。

（2）对于某些建立在J2EE或dotNet应用服务器上的应用，在应用服务器需要重启时，没有在测试之前首先进行一段时间“预热”。

2）调整系统运行环境和实现方法，执行测试。

这是性能调优的核心步骤。性能调优的目的是通过调整，提高应用系统的性能表现，对于一个应用系统来说，这种调整包括一下3个方面。

1⃣️硬件环境的调整：主要是对系统运行的硬件环境进行调整，包括改变系统运行的服务、主机设备环境（改用具有更高性能的机器，或者调整某些服务的物理内存总量，CPU数量等）、调整网络环境（更换快速的网络设备，或是采用更高带宽的组网技术）等。

2⃣️系统设置的调整：主要是对系统运行的基础平台设置进行调整，例如，根据根据应用需要调整UNIX系用的核心参数，调整数据库的内存迟大小，调整应用服务使用的内存大小，或是采用更高版本的JVM环境等。

3⃣️应用服务级别的调整：主要是对应用实现本身进行调整，包括选用新的架构、采用新的数据访问方式或修改业务逻辑实现方式等。

注意⚠️：实际生产环境上的部署完成的系统，调优的重点可能会放在硬件环境和系统设置上，以达到投入/产出比；但对于开发中的的应用，通过硬件环境和系统设置仍达不到用户要求已部署系统，还需要再应用级别上进行调整。

3）记录测试结果，进行分析

性能调优使用主要测试方法包括配置测试、负载测试、压力测试和失效恢复测试。

前端性能测试在使用上类似于性能调优的步骤，具体如下：

（1）通过前端性能统计数据或工具发现前端性能的问题

（2）根据问题进行前端性能的调整（通过修改前端实现方式，页面代码达成）

（3）验证前端性能是否达到预期的要求。

#### 2.2.4缺陷发现

缺陷发现性能测试应用领域的主要目的是通过性能测试的手段来发现系统中存在的缺陷。为了解决“应用在测试环境下非常正常，但是一旦交付给用护，就出现大量莫名其妙的错误”的一类错误。

如果测试环境正常，生产环境出现应用挂死，多人访问时速度时快时慢，多人访问时应用崩溃几率增大等问题，则基本上市由于并发时的线程锁，资源竞争或内存问题引起的。

该应用领域主要目的是发现缺陷，并没有可以参照的性能指标或是需要达到的性能目标。因此需要采用并发测试的方法。还需要关注压力及失效恢复过程中出现的问题，则可以采用压力测试和失效恢复测试方法。

#### 2.2.5性能基准比较

性能基准比较通常应用在敏捷开发过程中。敏捷软件开发采用“递增”的开发方式，由于很难在一开始就为每个迭代定于明确的性能需求，因此，在每个迭代中对应用进行性能检查，以保证应用的性能不会随着迭代的不断发生而变化是非常好的实践。

在实际操作中，可以将性能测试形成固定的脚本，并在固定的环境上对模块执行相应的性能测试，测试结果通过工具直接写入数据库并通过图形展现工具将其展现成折线图，其中可以直观的反映模块每个迭代中性能表现的变化，甚至可以做为验收条件的一部分。

另一方面，在敏捷软件开发过程中，用于设立性能基准比较的不仅仅是模块，还可以在单元测试中为给懂的函数设置性能基准比较。

![image-20190823165828448](/Users/apple/Library/Application Support/typora-user-images/image-20190823165828448.png)

## 三.性能计数器及性能分析方法

性能计数器（Counter）通常被用来衡量被测系统当前的状况和进行性能测试结果分析。单一的性能计数器通常反应了系统性能的一个侧面，在进行性能测试结果分析时，一般要对多个性能计数器进行分析。

### 3.1操作系统计数器及分析

操作系统计数器可用来监控操作系统级别上的系统性能表现。

#### 3.1.1windows操作系统的主要计数器

参考《软件性能测试过程详解与案件剖析》第三章，3.1小节

#### 3.1.2Unix/Linux操作系统的主要计数器

参考《软件性能测试过程详解与案件剖析》第三章，3.1小节

#### 3.1.3内存分析方法

内存分析用于判断系统有无遇到内存瓶颈，是否需要通过增加内存等手段提高系统性能表现。

内存分析的主要方法和步骤：

（1）查看Memory/Available Mbytes指标（Linux 是Free（KB））

该计数值是描述系统可用内存的直接指标，在对系统进行操作系统级别的内存分析时，首先通过该指标建立一个初步印象，了解性能测试过程中系统是否仍然有足够的内存可用。

如果该指标数据比较小，系统可能出现了内存方面的问题，这时需要继续依据以下步骤进一步的分析

（2）注意Pages/sec、Pages Read/sec 和 Page Faults/sec（Linux是（page）si和（page）so）

操作系统经常会利用磁盘交换的方式提高系统可用的内存量或内存的使用效率。windows和Linux都提供了类似的方法来支持磁盘交换计数，而这3个指标直接反应了操作系统进行磁盘交换的频度。

如果Pages/sec的计数持续高于几百？很可能会有内存方面的问题产生，但Pages/sec的值很大不一定表明内存有问题，而可能是运行时用内存映射文件的程序所致。Page Faults/sec值表示每秒发生页面失效的次数，页面失效次数越多，说明操作系统向内存中读取的次数越多。此时还需要查看Pages Read/sec的计数值，该计数器的阀值为5，如果计数值超过5，则可以判断存在内存方面问题。

（3）根据Physical Disk计数器的值分析性能瓶颈。

对Physical Disk计数器的分析包括对Pages Read/sec 和%Disk Time及Average Disk Queue Length 的分析，如果Pages Read/sec很低，同时%Disk Time和Average Disk Queue Length的值很高，则可能有磁盘瓶颈。但是如果队列长度增加的同时Pages Read/sec并未降低，则是由于内存不足。

#### 3.1.4处理器分析方法

处理器（CPU）也可能是系统的瓶颈，下面来看如何针对处理器进行分析，步骤如下：

（1）查看 System\%Total Processor Time 性能计数器的计数值

该计数器用于体现服务器整体的处理器利用率，对多处理器系统而言，该计数体现的是所有CPU的平均利用率。如果该值的数值持续超过90%，则说明整个系统面临着处理器方面的瓶颈，需要通过增加处理器来提高性能。

要注意的是，由于操作系统本身的特性，在某些多CPU系统中，该数据本身并不大，但若CPU之间的负载情况极不均衡，也应该是做系统产生了处理器方面的瓶颈。

（2）查看每个CPU的Processor\%Processor Time 和Processor\%User Time和Processor\%Privileged Time。

Processor\%User Time是指系统的非核心操作消耗CPU的时间，如果该值较大，可以考虑通过算法优化等方法降低该值。如果该服务器是数据库服务器，Processor\%User Time值大的原因可能是数据库的排序或是函数操作消耗了过多的CPU时间，此时可以考虑对数据库系统进行优化。

（3）研究系统处理器瓶颈。

查看System\%Processor Queue Length计数器的值，当该计数器的值大于CPU的数量的总数加1时，说明产生了处理器阻塞。在处理器的%Process Time值很高时一般都伴随着处理器阻塞，但产生处理器阻塞时，Processor\%Process Time 计数器的值并不一定很大，此时就必须查找处理器阻塞的原因。

%DFC Time 时另一个需要关注的内容，该计数器值越低越好。在多处理器系统中，如果该值大于50%并且Processor\%Process Time值非常高，则考虑加入一个网卡来提高性能。

#### 3.1.5磁盘I/O分析方法

磁盘I/O分分析方法介绍如下：

（1）计算每个磁盘的I/O数。

每磁盘的I/O数可用来与磁盘的I/O能力进行对比，如果经过计算得到的每个磁盘的I/O数超过了磁盘标称的I/O能力，则说明确实在磁盘的性能瓶颈。

![image-20190830111718611](/Users/apple/Library/Application Support/typora-user-images/image-20190830111718611.png)

（2）与Processor\Privileged Time 合并进行分析

如果在Physical Disk计数器中，只有%Disk Time值较大，其他值都比较适中，则硬盘可能是瓶颈。若几个值都比较大，且数值持续超过80%，则可能是内存泄漏。

（3）根据Disk sec/Transfer 进行分析

一般来说，定义Transfer数值小于15毫秒为优秀，介于15～30毫秒之间为良好，30～60毫秒之间为可以接受，超过60毫秒则需要考虑更换硬盘或硬盘的RAID方式了。

#### 3.1.6进程分析方法

针对内存、处理器和磁盘I/O进行分析后，接下来看看进程的分析方法。

（1）查看进程的%Processor Time值

每个进程的%Processor Time值反映出进程所消耗的处理器时间。将不同进程所消耗的处理器时间进行对比，可以容易地看出具体哪个进程在性能测试过程中消耗了很多的处理时间，从而可以根据此针对应用进行优化。

（2）查看每个进程产生的页面失效

可以用每个进程产生的页面失效（通过Process\Page Faulres/sec计数器活动）和系统的页面失效（通过Memory\Page Faulres/sec计数器获得）的比值，来判断乃个进程产生了最多的页面失效，该进程要么是需要大量内存的进程，要么是非常活跃的进程，可以对其进行重点分析。

（3）了解进程的Process\Private Bytes

Process\Private Bytes是指继承所分配的无法与其他进程共享的当前字节数量。该计数器主要用来判断进程在性能测试中有无内存泄漏。例如，对于一个IIS之上的web应用，可以重点监控inetinfo进程的Private Bytes，如果在性能测试过程中，该进程的Private Bytes计数器值在不断增加，或是性能测试停止一段时间，该进程Private Bytes仍然持续在较高水平，则说明应用存在内存泄漏。

#### 3.1.7网络分析方法

Network Interface/Bytes Total/sec 为发送和接收字节的速率（包括帧字符在内）。可以通过该计数器的值判断网络连接速度是否是瓶颈，具体操作方法是用该计数器的值和目前网络的带宽进行比较

### 3.2应用服务计数器

最常用的服务器包括IIS、Tomcat、Weblogic、等J2EE应用服务器。

### 3.3数据库服务器计数器

## 四.性能测试工具原理

性能测试工具分为：服务端性能测试工具和前端幸好你能测试工具两大类。服务端性能测试工具主要支持产生压力和负载，录制和生成脚本，设置和部署场景，产生并发用户和向系统施加持续的压力；而前端性能测试工具则不关心系统的压力和负载，只需要关心浏览器等客户端工具对具体的需要展现的页面处理过程

### 4.1服务端性能测试工具

服务端性能测试一般包括以下部件：

**虚拟用户脚本产生器（Virtual User Generator）**

**压力产生器（Player）**

**用户代理（Agent）**

**压力调度和监控系统（Conductor）**

**压力结果分析工具（Analysis）**

![image-20190902172510821](/Users/apple/Library/Application Support/typora-user-images/image-20190902172510821.png)

### 4.2前端性能测试工具原理

客户端花费的用于加载和展现的时间就是前端响应时间，而客户端的性能表现通常被称为前端性能。

### 4.3选择服务性能测试脚本使用的协议

选择性能测试脚本协议最简单的原则是：选择客户端和服务器通信时所采用的最上层的协议。例如：Web应用的客户端和服务器之间通常是使用HTTP/HTTPS协议进行通信的，但HTTP/HTTPS协议是基于TCP协议上的应用层协议，因此在LoadRunner工具中，采用Socket或HTTP/HTTPS协议上的应用层协议，因此在LoadRunner工具中，采用Socket或HTTP/HTTPS协议均能录制得到脚本。另一个例子是使用自定义的TCP或UDP协议进行通讯的C/S应用（如腾讯的QQ），在TCP或UDP协议层上一定可以进行录制等方式得到客户端与服务端之间的通信协议，并使用符合协议要求的编码与解码方式产生和解析通信数据包。

选择性能测试脚本录制协议时，有几点必须说明的内容：

（1）使用socket协议可以对任何应用通信进行录制，但这种录制生成的脚本很可能没有任何意义。

（2）在对应用的通信进行录制生成脚本后，对脚本进行回放，有时会出现回放无法继续的情况（停留在某个步骤无法进行下去），此时应该考虑是否使用了合适的协议，很可能是由于协议选择不正确或是不全面，导致部分通信没有录制成功。

### 4.4性能测试工具的选择与评估

选择那种工具通常具有三个层次的意义：第一，创建还是购买？第二，如果和购买，如何选择？第三，如果自行创建，如何创建？

#### 4.4.1创建和购买的选择

考虑情况：

1.如果需要的是一个仅用于本次项目测试的工具，或是被测系统使用了比较特殊的协议等，可以考虑自行创建需要的测试工具；

2.如果需要作为第三方接受委托进行性能测试，选择被广发接受的商业工具可能会让委托方更有信息；

3.如果需要以最快的速度建立立即可用的组织的性能测试环境，选择商业工具应该是比较合适的方案

4.如果希望建立一个能够长期发展，并能适应产品和组织变化的性能测试体系，则基于开源工具创建适合组织的工具体系可能是最佳的方式。

#### 4.4.2测试工具的评估和选择过程

评估步骤：

1.列出需要的工具功能列表

可以从以下几个方面考虑需要的功能：

（1）工具是否支持被测系统运行的平台（软硬件环境、数据库环境）吗？

（2）工具能否支持被测系统使用的协议吗？

（3）工具能否支持特殊要求（如防火墙、负载均衡、动态页面生成等）吗？

（4）工具能够提供对服务器、应用服务或数据库类型计数器的监控吗？

（5）工具使用的脚本语言功能完善吗？

对于开源性能测试工具，除了对其具有的功能进行考虑外，还需要从工具的可维护性和社区支持等方面进行考虑，具体如下。

（1）工具是否有相对固定的维护成员？项目活跃吗？工具社区是否能提供足够的支持？

（2）工具采用的是何种编程语言？本组织有合适的资源对工具进行维护和支持吗？

（3）工具是否具有良好的结构和拓展性，以便于二次开发、功能添加或将其集成到组织的自动化体系中

（4）工具采用的是何种开源许可协议（License）？这种开源许可协议是否会给使用和二次开发带来法律上的风险和问题？

2.工具比较

对工具的比较内容包括以下几个方面：

（1）功能比较。

（2）工具能获取支持的比较。

（3）供应商的信誉。

（4）工具的维护成本。

性能测试工具的功能评估：

![image-20190918142648246](/Users/apple/Library/Application Support/typora-user-images/image-20190918142648246.png)

3.成本分析

## 五.性能测试的组织

### 5.1性能测试团队的人员构成

一个性能测试团队包括以下角色：

![image-20190918145704557](/Users/apple/Library/Application Support/typora-user-images/image-20190918145704557.png)

### 5.2性能测试过程模型（PTGM）

第一种模型基于自动化测试生命周期方法（ATLM）和被广泛采用的TMap模型，按照ATLM的描述方法对性能测试过程进行建模，面向传统软件过程中的、主要集中在系统或验收测试阶段进行的性能测试，我们把这种模型成为性能测试过程通用模型（PTGM）。另一种模型被称为敏捷性能测试模型（APTM）与PTGM这个基于过程的模型不同，APTM模型检查表、活动列表和建议工具列表帮助敏捷过程中的工程师更好地开展性能测试。

PTGM示意图：

![image-20190918154336456](/Users/apple/Library/Application Support/typora-user-images/image-20190918154336456.png)

#### 5.2.1测试前期准备阶段

在测试前期阶段至少要完成两方面的工作：保证系统稳定和建立合适的测试团队。性能测试一般时软件系统已经开发或事是不熟完成之后的测试，要求被测对象至少具有一定的稳定性，在功能上基本满足需求。对一个很不稳定或还处于“半成品”状态的软件系统进行测试，没有太大的意义。

具体来说，测试前期阶段包括以下活动。

（1）系统基础功能验证。

（2）组建测试团队

（3）测试工具确认

（4）性能预备测试（可选活动，相当于随机测试，对系统的性能有个初步印象）

#### 5.2.2测试工具引入阶段

测试工具引入阶段包括下列活动：

（1）选择工具。

性能测试一定会使用自动化测试手段和自动测试工具。

（2）工具应用的技能培训。

（3）确定工具的应用过程。

确定该活动需要确定性能测试工具在测试中的具体应用范围，工具使用过程中的问题解决方法等内容。

#### 5.2.3测试计划阶段

测试计划活动分解为以下活动：

##### （1）性能测试领域分析

在性能测试计划阶段，首先要执行的活动是根据性能测试所期望达到的目的，分析出性能测试的应用领域。

测试的目的是明确验证系统在固定条件下的性能能力的，属于能力验证领域，该领域常见于对特定环境上部署系统的性能验证测试；

测试目的是了解系统性能能力的可拓展性、系统在非特定环境下的性能能力的，属于规划能力领域，该领域常见于对应用性能可拓展性的测试；

测试目的是通过测试（发现问题）-调优（调整）-测试（验证调优效果）的方法提高系统性能能力的，属于性能调优领域；

测试目的是通过性能测试手段发现应用的缺陷，属于发现缺陷领域。

![image-20190918165608058](/Users/apple/Library/Application Support/typora-user-images/image-20190918165608058.png)

##### （2）用户活动剖析与业务建模

用户活动剖析的方法大体分两种：系统日志分析和用户调查分析。

系统日志分析是指通过应用系统的日志了解用户的活动，分析出用户最关注、最常用的业务功能以及达到业务功能的操作路径；

用户调查分析是在不具备系统日志分析条件（如该系统尚未交付用户运行实际业务）时采用的一种估算方法，可以通过用户调查文件、同类型系统对比的方法获取用户最关注、最常用的业务功能等内容。

注意⚠️：业务建模是对业务系统行为及其实现方式和方法建模，一般采用流程图的方式描绘出各进程之间的交互关系和数据流向。对复杂的业务系统来说，业务建模可以将业务系统清晰地呈现出来，为性能测试提供最直观的指导。

##### （3）确定性能目标

性能测试目标根据性能测试需求和用户活动分析结果来确定，确定性能测试目标的一般步骤是首先从需求和设计中分析出性能测试需求，结合用户活动剖析与业务建模的结果，最终决定性能测试的目标。

注意⚠️：对一个性能测试需求描述比较清楚的是：该应用能够以1秒的最大响应时间处理200个并发用户对业务A的访问，此时服务器的CPU占用不超过75%，内存使用率不超过70%；峰值时刻有400个用户，允许响应时间延长为3秒，此时服务器CPU不超过85%，内存使用率不超过90%。

##### （4）制定测试时间计划

该活动给出性能测试的各个活动起止时间，为性能测试的执行给出时间上的估算。

#### 5.2.4测试设计与开发阶段

性能测试的设计与开发阶段包括测试环境设计，测试场景设计，测试用例设计，以及脚本、辅助工具开发活动。

##### （1）测试环境设计

测试环境设计是测试设计中不可缺少的环节。性能测试的结果与测试环境之间的关联性非常大，无论是哪种领域内的性能测试，都必须首先确定测试环境。

对于能力验证领域的性能测试来说，测试首先明确了是在特定的部署环境上进行，因此不需要特别为性能测试设计环境，只需要保证用于测试的环境与今后系统运行的环境中一致即可。

对于规划能力领域的性能测试来说，测试环境不特定，但也需要设计一个基准的环境。

对于性能调优领域的性能测试来说，因为调优过程是一个反复的过程，在每个调优小阶段的末尾，都需要有性能测试来衡量调优的效果，因此必须在开始就给出一个用于衡量的环境标准，并在整个调优过程中保证每次测试时的环境保持不变。

这里所说的测试环境设计包括系统的软硬件环境，数据库环境设计还包括环境的维护方法。其中数据库设计是非常关键但又是最容易被忽视的问题，设想一下，系统运行在一个已有50000条数据的数据库和一个几乎为空的数据库环境上，其执行查询、插入和删除操作的响应时间显然是不同的。

##### （2）测试场景的设计

测试场景模拟的一般是实际业务进行的剖面，包括业务、业务比例、测试指标的目标以及需要在测试过程中进行的监控的性能计数器。

![image-20190918204408822](/Users/apple/Library/Application Support/typora-user-images/image-20190918204408822.png)

场景可被看作是用户实际运行环境的"剖面"，也就是说，场景体现的是用户实际运行环境中具有代表性的业务使用情况。用户场景一般由用户在某一个时间段内的所有业务使用情况组成。

##### （3）测试用例设计

在设计完成测试场景之后，为了能够把场景通过测试工具体现出来，并能用测试工具顺利进行测试执行，有必要针对每个测试场景规划出相应的工具部署、应用部署、测试方法和步骤，该过程就是测试用例设计活动。

##### （4）脚本和辅助工具开发

脚本和辅助工具的开发是测试执行之前的最后步骤，测试脚本是对业务操作的体现，一个脚本一般就是一个业务的过程描述。测试脚本的开发通常基于"录制"，依靠工具提供的录制功能，可以将需要性能测试关注的业务在工具的录制下操作一遍，然后基于该录制后的脚本，对其进行修改和调试，确保其可以在性能测试中顺利使用。

#### 5.2.5测试执行与管理

测试执行与管理过程用于建立合适的测试环境，部署测试脚本和测试场景，执行测试并记录测试结果。

##### （1）建立测试环境

该活动用于搭建需要的测试环境，在设计完成用例之后就会开始该活动。该活动是一个持续的活动，在测试过程中，可能会根据测试需求进行环境上的调整。

建立测试环境一般包括硬件，软件系统环境的搭建，数据库环境建立，用用系统的部署，系统设置参数的调整以及数据环境准备等几个方面的工作内容。

注意⚠️：一般来说，在测试环境的多台设备间实现时间同步的方法有如下几种。

 ➢通过Windows的域方式实现时间同步：将所有机器加入同一个域，可以利用windows的域机制实现时间通过。

➢通过ntp协议实现unix主机之间的时间同步：unix主机可以通过ntp洗衣实现相互间的时间同步，具体操作方式可以查看Man ntp。

➢通过开源工具NetTime实现时间同步：NetTime是一个可以运行在Windows环境下的时间同步工具，该工具使用ntp协议，因此可以用来实现unix和Windows混合网络时间同步

测试环境的维护是另一个比较困难的问题。性能测试中使用的数据量巨大，每次运行测试都可能会产生大量的测试数据，而且性能测试可能会需要部署大量的测试辅助工具和程序。为了测试结果的可比性，一般都需要在每次运行测试结束后恢复初始的测试环境，如果管理不善，该恢复工作经常会引起极大的混乱。

我们的做法是使用检查列表（Checklist），在每次测试运行完成，准备进行下一轮的测试运行之前，用Checklist检查环境可用性，例如：

![image-20190919161413408](/Users/apple/Library/Application Support/typora-user-images/image-20190919161413408.png)

##### （2）部署测试脚本和测试场景。

部署活动最终需要保证场景和设计的一致性，保证需要监控的计数器都已经部署好相应的监控手段。

##### （3）执行测试和记录结果

#### 5.2.6测试分析

性能测试的挑战行很大程度上体现在对测试结果的分析上，可以说，每次性能测试结果的分析都需要测试分析人员具有相当程度的对软件性能、软件架构和各性能指标的了解。

性能测试分析需要借助各种图表，一般性能测试工具都提供了报表模块来生成不同的图案。如果是采用自己编写的脚本获取性能计数器的值，则可以通过Excel等数据处理软件生成图标。

注意⚠️：性能分析的通用方法之一是拐点分析。拐点分析法是一种利用性能计数器曲线上的拐点进行性能分析的方法，其基本思想是基于以下事实：性能产生瓶颈时由于某个资源的使用达到了极限，此时的表现是随着压力增大系统性能表现急剧下降，因此，只要关注性能表现上的拐点，获得拐点附近的资源使用情况，就能够定位出系统的性能瓶颈。拐点分析法在确定引起性能瓶颈的系统资源方面能发挥一定的作用，但由于智能定位到资源上的制约，而不能直接定位到引起制约的原因，因此，该方法还必须配合其他方法使用，才能最终确定引起性能瓶颈的最根本原因。可用于进行拐点分析的图标包括负载-响应时间曲线、负载-吞吐量曲线等。

### 5.3敏捷性能测试模型（APTM）

敏捷性能测试模型（APTM）不仅仅适用于指导敏捷过程中的性能测试的开展，也同样适合在飞敏捷的环境下尽早建立性能测试，今早发现系统可能的性能问题。

##### 5.3.1APTM的检查表

做为一种常用的工具，检查表可以为使用者提供框架和指导。敏捷注重过程和灵活性，因此，在采纳敏捷的APTM模型中，不倾向于定义严格的过程，而是使用检查表对敏捷性能测试进行指导。

APTM的检查表可以看作是敏捷性能测试的总体原则。APTM检查表内容体现了敏捷性能测试中的倾向：在迭代中设立性能目标，通过性能测试验证性能目标；在各个层面上建立性能测试；尽可能通过自动化的方式建立敏捷环境下的性能测试支持环境。

APTM中常见问题介绍如下。

➢在每个迭代中是否有明确的性能测试任务（包括函数级别的性能测试）

并非每个迭代都需要站在性能测试上花费许多时间，但不管怎么样，在每个迭代中考虑性能测试任务总是能够帮助开发团队更好的思考项目的性能要求。

➢每个迭代的验收测试标准中是否有性能验收测试标准？

敏捷的每个迭代都需要有明确的标准决定一个迭代是否可以结束，该标准就是迭代的验收测试标准。只有在验收测试标准中明确设置了具体的性能标准，性能测试要求才能在每个迭代中得到实现。

➢是否在单元、接口和系统级别分别设置了相应的性能测试？

APTM建议至少站在单元、接口和系统3个层次设置相应的性能测试。在单元层面，性能测试通过对函数的运行时间评估来进行，涉及到的依赖通过Mock来解决；在接口层面，性能测试要求设置接口的运行环境，在少量用户的情况下，检查接口的性能；在系统层面，则要求接近生产环境的性能测试环境，通过模拟真实的用户负载来进行测试。

➢是否已经建立合适的性能测试支持环境帮助实施各个层次的性能测试？

敏捷环境下的测试高度依赖自动化。一般而言，性能测试支持环境包括持续集成环境、性能测试运行环境、基准比较环境和测试环境管理几个主要部分。其中：

**性能测试运行环境**：由执行性能测试的工具构成，能够提供从单元级别性能测试到系统级别性能测试的测试执行支持；

**基准比较环境**：与应用的分布方式相关，在应用每次发布时对其主要的性能指标进行验证，保证新发布版本主要性能指标不比原来的版本差；

**测试环境管理**：主要提供各个层面性能测试环境的建立功能，包括单元和接口级别的Mock工具、数据生成工具、测试环境备份和恢复工具等。

![image-20190919173147256](/Users/apple/Library/Application Support/typora-user-images/image-20190919173147256.png)

➢性能测试结果报告是否包含在反馈体系中？

做为敏捷的核心价值观之一，反馈为敏捷开发团队提供了良好进度和质量评估机制，持续集成（CI）就是一个典型且有效的反馈机制。将性能测试结果报告包含到反馈体系中可以大大提高性能测试的价值，帮助开发团队更好地管理性能。

##### 5.3.2 APTM中的活动

APTM中的主要活动如下：

（1）识别性能测试任务优先级。

（2）设置环境与执行测试。

（3）分析测试结果与报告

（4）在下一个迭代中重复（1）～（3）步骤

1.性能测试任务优先级

识别任务优先级是敏捷开发的每个迭代中首先要做的事情。敏捷遵循"交付价值"原则，在每个迭代中需要根据其产生的价值决定加入哪些具体的性能测试任务。敏捷开发方法中对于估算和确定优先级的方法都可以用来帮助是被和确定性能测试任务的优先级。

如前所述，是否在迭代中包含某个性能测试任务是由该任务的价值决定的，为准确评估任务的价值，需要首先了解项目的上下文，被测系统以及性能测试目标，可通过以下问题更好的了解。

➣客户的期望是什么？客户希望以怎样的方式验证性能？客户是否希望每个迭代中对性能进行评估？

➣发布流程是怎么样的？性能测试需要关心那些构建（持续集成、日构建、专为性能测试发布的构建、发布构建）

➣性能测试目标是如何分解到每个迭代中的？开发工程师会在单元测试中包含性能验证吗？

➣在本迭代之中，团队最关心的事情时验证性能、度量性能、还是对性能调优？

➣迭代中的任务优先级如何评估的？

2.配置环境与执行环境

3.分析测试结果与报告

##### 5.3.3环境与工具

1.持续集成环境

持续集成环境并非是为了敏捷性能测试专门设置的。在敏捷体系中，持续集成是一种最佳时间，其提供了对产品质量的持续评估与反馈体系。持续集成通过持续构建的方式保证开发工程师代码能够经常性的进行集成，在集成过程中尽可能早的发现问题。对敏捷性能测试来说，持续集成通过及时的反馈，保证性能测试成为持续的产品质量评估体系的一部分，从而使性能测试在敏捷过程中发挥更大的价值。

2.测试执行环境

（1）单元层面的性能测试工具

单元层面的性能测试主要用来对应用的函数或模块进行性能评估。对算法的性能评估就是该层面性能测试的典型例子。需要说明的是，单元层面的性能测试往往需要Mock工具的支持，Mock工具可以减少应用对环境的依赖性，并且增加性能测试的可靠性。

（2）接口层面的性能测试工具

（3）系统层面的性能测试工具

3.基准比较环境

所谓基准比较，是指基于构建建立的一套比较机制。例如，可以为应用的发布版本建立一个基准性能测试，在相同的测试环境和负载下评估每个发布版本的主要性能指标，各个版本的主要性能指标构成的曲线可以清晰的现实应用的性能变化趋势，甚至可以作为版本是否能够发布的评价标准。

4.测试环境管理

## 六 Web前端性能

### 6.1前端性能示例

性能测试工具：

Apache Benchmark（ab）得到的响应时间仅为从请求发出开始到接收到HTML的最后一个字节所消耗的全部时间。ab命令行如下：

ab -c 【并发用户数】 -n 【发出请求数量】 【被测试页面的URL】

FireBug：

DOMContentLoaded事件：当初始的 HTML 文档被完全加载和解析完成之后，DOMContentLoaded 事件被触发，而无需等待样式表、图像和子框架的完成加载。

onload事件：在页面和图片加载完成后加载。

对Web应用前端性能的研究不是为了准确地得到一个响应时间数据，实际上，Web性能一部分取决于Web服务器和应用服务器（建立连接/下载资源文件），另一部分取决于浏览器的实际机制/Web页面上的JS文件执行等。取决于web服务和应用服务器的响应时间与服务器的负载和压力相关；而取决于浏览器实现机制与JS文件执行所需要的时间则几乎与服务器负载和压力无关。对于后者的研究正是本章所探讨的内容要逃的目的不是得到这部分响应时间的准确数据，而是拖动更好的web应用的前端性能，减少总响应时间。

### 6.2HTTP概要

HTTP用于传输WWW方式的数据，该协议采用了请求/响应模型。HTTP协议本身是一种非面向连接的协议，每个HTTP请求之间都是独立的。

#### 6.2.1HTTP协议结构

1.请求报文格式

请求报文格式如下：

![image-20191028140129718](/Users/apple/Library/Application Support/typora-user-images/image-20191028140129718.png)

请求行为的格式：

Method 【分隔符】Request -URI 【分隔符】HTTP-VersionCRLF

http报文主体包含了HTTP请求的内容。对于GET等方法来说，报文主体为空；对于POST方法来说，报文主体则包含需要发送给服务器的数据。

2.响应报文的格式

响应报文的格式如下：

![image-20191030114053446](/Users/apple/Library/Application Support/typora-user-images/image-20191030114053446.png)

响应报文状态码：

1XX：信息响应类，表示接受到请求并且继续处理。

2XX：处理成功响应类，表示动作被成功接收、理解和接受。

3XX：重定向响应，表示完成指定的动作，必须接受进一步处理。

4XX：客户端错误，表示客户请求包含语法错误或不能正确执行。

5XX：服务端错误，表示服务器不能正确执行一个正确的请求。

响应头则给出了服务器本身的一些信息，返回HTML或其他数据内容包含在报文主体中。

#### 6.2.3与前端性能相关的头信息

##### 1.Accept-Encoding

Accept-Encoding是浏览器发出的请求头中包含的头信息域之一，用于告诉服务器所接受的页面文件的编辑方式，如Accept-Encoding：gzip，deflate就是告诉服务器，浏览器能够接受不压缩和使用gzip两种方式的页面内容。页面压缩和不压缩到底能够带来多大的性能差距？压缩能够大大提高浏览器性能。

⚠️：目前主流浏览器都是支持对页面的gzip压缩方式的，因此在服务端需要确保返回的页面在这种情况下已经进行gzip压缩。

#### 2.Connection

HTTP协议是一种非面向连接的、无状态的协议。当Connection的值设定为keep-alive时，浏览器与服务器之间约定使用持久连接。

#### 3.Expires

HTTP响应数据头中包含一个Expires域，该域的值用于指示返回数据到期时间。⚠️浏览器缓存机制：Expires头给出的信息就是依据：当当前时间小于Expires指定的时间时，浏览器从缓存中直接获取相应的资源文件或HTML文档；而当当前时间大于Expires指定时间时，浏览器向服务器发送请求获取该资源。

### 6.3浏览器打开URL的方式

#### 6.3.1连接到URL所在服务器

用户在地址栏中输入一个URL，并单击GO按钮要求浏览器打开该URL后，浏览器做的第一件事是寻找该URL所在的服务器。通过向DNS服务器查询，浏览器可以获得该URL所在网站的IP地址。然后浏览器向该地址发起连接请求，建立到服务器的连接。

#### 6.3.2获取页面对应的HTML文档

当连接建立后，浏览器向服务器发送HTTP请求，请求URL对应的HTML文档。不管请求的URL是一个静态的HTML文件，还是动态脚本（ASPX、PHP或JSP），服务器返回该浏览器的一定是一个HTML文档。该HTML文档就是浏览器需要呈现的页面。

#### 6.3.3解析文档并获取所需要的资源

浏览器在获取HTML文档后会对文档进行解析，目的是知道该页面需要哪些资源以及生成DOM树。当DOM树生成后，DOMContentLoaded事件触发。

并非所有元素都可以被并行下载。一般情况下，页面包含两类需要被执行的JS脚本，一类是直接用<script>标签标示的内嵌JS语句；另一类是引用的外部JS文件。

#### 6.3.4页面上的JS文件与CSS文件

对于浏览器而言，在处理页面上的JS文件合格JS代码时，只需要保证一下两点：

（1）所有JS代码按照其在HTML文档中出现的顺序执行，这样可以保证JS文件之间存在的依赖关系在执行时不会被破坏。

（2）JS文件在执行时，其依赖的DOM树已经建立好。

#### 6.3.5onload事件

当HTML文档解析完成，生成DOM树，所有页面需要的资源文件都已经成功下载和执行（对于JS文件）后，浏览器会发出onload事件并回调HTML文档中的onload函数。

### 6.4提高前端性能的方法

提升前端的性能，有两大思路：

（1）减少页面加载所需要的时间

（2）提升用户观感，让用户觉得页面更快

#### 6.4.1减少网络时间

1.使用DNS缓存技术

2.减少需要传输文件的尺寸

3.加快文件传输速度

#### 6.4.2减少发送的请求数量

1.利用浏览器缓存

➢保证服务端返回资源的响应头带Expires信息，是的资源可以被缓存。

➢用引用方式使用样式表和JS脚本。如果使用内嵌的样式表和JS脚本，每次HTML文档的变化都会导致样式表和JS脚本需要重新加载，无法充分利用缓存。当然，在没有缓存或样式表与JS脚本需要重新加载，用引用方式使用样式表和JS脚本反而会导致更多的HTTP请求。

➢使用更多的URI可以被浏览器缓存。许多网站使用脚本生成需要返回的图片或JS资源文件，而该脚本所在的URI又附带一些经常变换的参数，这导致这些内容无法被缓存（缓存要求URI严格一致）。

2.使用合并的图片文件

#### 6.4.3提高浏览器下载的并发度

1.JS文件放在HTML文档的后面

2.使用多个域名

#### 6.4.4让页面尽早开始显示

（1）将样式表的引用放在HTML的头部（如放在<head>标签中）

（2）将样式表的引用放在HTML文档的最后。

